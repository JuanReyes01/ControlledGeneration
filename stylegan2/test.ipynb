{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import dnnlib\n",
    "import legacy\n",
    "\n",
    "# Load pre-trained model\n",
    "network_pkl = 'ffhq.pkl'\n",
    "device = torch.device('cuda')\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)  # type: ignore\n",
    "\n",
    "# Function to generate latent vectors and corresponding images\n",
    "def generate_latents_and_images(num_samples, model):\n",
    "    latents = []\n",
    "    images = []\n",
    "    for _ in range(num_samples):\n",
    "        z = np.random.randn(1, model.z_dim)\n",
    "        z_tensor = torch.from_numpy(z).to(device)\n",
    "        img = model(z_tensor, None, truncation_psi=0.7, noise_mode='const')\n",
    "        latents.append(z)\n",
    "        images.append(img.cpu().detach().numpy())  # Move image tensor to CPU before converting to numpy\n",
    "    return np.array(latents), np.array(images)\n",
    "\n",
    "# Generate latent vectors for smiling and non-smiling images\n",
    "num_samples = 100  # Number of samples for each class\n",
    "latents_smiling, images_smiling = generate_latents_and_images(num_samples, G)\n",
    "latents_not_smiling, images_not_smiling = generate_latents_and_images(num_samples, G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create labels\n",
    "labels_smiling = np.ones(num_samples)\n",
    "labels_not_smiling = np.zeros(num_samples)\n",
    "\n",
    "# Combine data\n",
    "latents = np.vstack([latents_smiling, latents_not_smiling])\n",
    "labels = np.hstack([labels_smiling, labels_not_smiling])\n",
    "\n",
    "# Flatten latent vectors for linear regression\n",
    "latents_flat = latents.reshape(latents.shape[0], -1)\n",
    "\n",
    "# Fit linear regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(latents_flat, labels)\n",
    "\n",
    "# Extract direction vector\n",
    "direction_vector = regressor.coef_.reshape(latents.shape[1:])\n",
    "np.save('smile_direction.npy', direction_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import dnnlib\n",
    "import legacy\n",
    "import PIL.Image\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define the function to convert tensor to image\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor.squeeze(0).detach().cpu()  # Move tensor to CPU\n",
    "    tensor = (tensor + 1.0) * 127.5\n",
    "    tensor = tensor.clamp(0, 255)\n",
    "    tensor = tensor.to(torch.uint8)\n",
    "    tensor = tensor.permute(1, 2, 0)\n",
    "    return PIL.Image.fromarray(tensor.numpy())\n",
    "\n",
    "# Load pre-trained model\n",
    "network_pkl = 'ffhq.pkl'\n",
    "device = torch.device('cuda')\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)  # type: ignore\n",
    "\n",
    "# Load pre-trained model\n",
    "# Assume G is already loaded as in the previous examples\n",
    "\n",
    "# Function to generate latent vectors and corresponding images\n",
    "def generate_latents_and_images(num_samples, model):\n",
    "    latents = []\n",
    "    images = []\n",
    "    for _ in range(num_samples):\n",
    "        z = np.random.randn(1, model.z_dim)\n",
    "        z_tensor = torch.from_numpy(z).to(device)\n",
    "        img = model(z_tensor, None, truncation_psi=0.7, noise_mode='const')\n",
    "        latents.append(z)\n",
    "        images.append(img.cpu().detach().numpy())  # Move image tensor to CPU before converting to numpy\n",
    "    return np.array(latents), np.array(images)\n",
    "\n",
    "# Generate latent vectors for samples\n",
    "num_samples = 100  # Number of samples for each class\n",
    "latents, images = generate_latents_and_images(num_samples, G)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit linear regression model for age\n",
    "regressor_age = LinearRegression()\n",
    "regressor_age.fit(latents_flat, age_labels)\n",
    "\n",
    "# Extract direction vector for age\n",
    "age_direction = regressor_age.coef_.reshape(latents.shape[1:])\n",
    "np.save('age_direction.npy', age_direction)\n",
    "\n",
    "# Fit linear regression model for gender\n",
    "regressor_gender = LinearRegression()\n",
    "regressor_gender.fit(latents_flat, gender_labels)\n",
    "\n",
    "# Extract direction vector for gender\n",
    "gender_direction = regressor_gender.coef_.reshape(latents.shape[1:])\n",
    "np.save('gender_direction.npy', gender_direction)\n",
    "\n",
    "\n",
    "# Manipulate latent vectors to control age and gender\n",
    "z_target = np.random.randn(1, G.z_dim)  # Random latent vector for demonstration\n",
    "z_target += age_intensity * age_direction  # Manipulate age\n",
    "z_target += gender_intensity * gender_direction  # Manipulate gender\n",
    "\n",
    "# Generate new image\n",
    "z_target_tensor = torch.from_numpy(z_target).to(device)\n",
    "img_target = G(z_target_tensor, None, truncation_psi=0.7, noise_mode='const')\n",
    "\n",
    "# Convert and save the manipulated image\n",
    "img_target_pil = tensor_to_image(img_target)\n",
    "img_target_pil.save('target_image.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
